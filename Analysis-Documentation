Provide a concise written report that includes:
● Justification for your data structure choices
● Analysis of time and space complexity
● Performance comparison between methods or all the implementations
considered
● Discussion of limitations and potential improvements


Exact Match Query: 
The Exact Match Query method works by implementing the data in terms of a HashMap. Initially, I was debating between using a HashMap and a TreeMap, but a Hashmap has a lower average time complexity O(1) vs O(logn) for TreeMaps and a lower memory overhead. While the rest of the methods in this classed using TreeMap, that is because RangeQuery and averageViewQuery, relied on finding a subset or range of data. The Exact Match query
doesn't require a range, and thus doesn't require and ordered data set, making Hashmap and unordered dataset with faster lookup more effective. This method  works by first making a list of all of the songs under a certain year, using the.get() method on the hashmap, which is O(1). Next the for loop runs through those songs and sees if their artists are the same, this for loop has a time complexity of O(m), m being the number of  items in the songsYear list (or the amount of songs that were released that year). This means the total time complexity is O(m), which is better than what it would have been with Hashmap, where the .get() method would have been O(logn) instead of constant, meaning the total time complexity would have been O(logn+ m). Overall, a limitation of this method using Hashmap may be that the other methods in the class require TreeMap, so we must create both data structures instead of just one.  

Range Query:            

Originally, I was planning on using a simple array list and for loops to search through all of the data and reutrn a list of data that fits within our range. 
So for example, I started creating a new ArrayList called newList, and then had a for loop where for each row in the database, if the 4th column of data, or data[3] was between the start and end year (inclusive), data[3] would be added to the newlist. I had even considered using a HashSet in order to avoid any duplicates. With this execution, the time complexity would have been O(n) because there is a for loop which executes n number of times, and the rest is all constant, such as appending to the end of an ArrayList.

However, while trying to make this as efficient as possible, I came across using TreeMaps. My current implementation involves using a TreeMap, that keeps the 
keys in their natural order, which can be beneficial for the future if we also wanted to sort the data. In my TreeMap, the key is the year, and the value is a list of all of the songs that were  released in that year. So for eaxmple, if 4 songs were released in 2010, those four songs would be the value to the key "2010".
We can break the time complexity apart into two different parts, one is the setup and the other is the actual query method. For the setup of the TreeMap, it would
be O(n) because there are n number of rows/data points to go through, and the TreeMap has to go through all of the rows, determine if it's already in the list, and
if not, then add it. This would go through every single row and essentially initialize the TreeMap. However, we only have to do that once. After that, we can 
simply look at the query method runtime. For the time complexity here, it would be O(log n + k). In a TreeMap, most operations, such as add and put, are O(log n), where n is the amount of data/rows in the database. However, because we will be iterating over the number of years within the range, this would be O(k). Here, k is representing the range of years. Since we don't know for how many years, we can't determine which is more dominant. However, in such a large dataset, it is 
much more likely that k is relatively smaller compared to n, so we know that using a TreeMap implementation is much better (especially considering the size of 
our dataset). Hence, although the setup for a TreeMap is O(n), while going through the query methods, particularly for a large dataset, a TreeMap will prove to be much more efficient than a simple ArrayList and multiple iterations.

A limitation is that TreeMap can take up higher memory overhead, and compared to a HashMap with O(1) or constant time operations, it's relatively slow. Duplicates 
currently aren't allowed, so if we wanted to see how many times, it could be a bit problematic. A potential improvement is 

Now I have a class called...

averageViewQuery:

In class, using Binary Search Trees for range queries was stressed. Therefore, because averageViewQuery must get a range of values and find the average value of the views within that range, I decided to use a TreeMap, which uses a binary search tree.
I considered potentially using a linked data structure, such as an ArrayList or linked list. I quickly ruled out using a linked list when I considered the runtime complexty, which would be O(n) to find only 1 element. While I could have used an ArrayList and a for loop, that option did not seem the best option because the runtime of using a for loop to get all the necessary values from my ArrayList would be O(n).

Therefore, I used a TreeMap to store my data. The treemap keeps the keys in their natural order. The keys are the year and the values are lists of all the songs realeased during that year.
